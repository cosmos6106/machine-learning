---
title: "Machine Learning Learning Lab 1 Overview: Prediction"
subtitle: "Overview Presentation"
author: "**Dr. Joshua Rosenberg**"
institute: "LASER Institute"
date: '`r format(Sys.time(), "%B %d, %Y")`'
output:
  xaringan::moon_reader:
    css:
     - default
     - css/laser.css
     - css/laser-fonts.css
    lib_dir: libs                        # creates directory for libraries
    seal: false                          # false: custom title slide
    nature:
      highlightStyle: default         # highlighting syntax for code
      highlightLines: true               # true: enables code line highlighting 
      highlightLanguage: ["r"]           # languages to highlight
      countIncrementalSlides: false      # false: disables counting of incremental slides
      ratio: "16:9"                      # 4:3 for standard size,16:9
      slideNumberFormat: |
       <div class="progress-bar-container">
        <div class="progress-bar" style="width: calc(%current% / %total% * 100%);">
        </div>
       </div>
---
class: clear, title-slide, inverse, center, top, middle

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```

```{r, echo=FALSE}
# then load all the relevant packages
pacman::p_load(pacman, knitr, tidyverse, readxl)
```

```{r xaringan-panelset, echo=FALSE}
xaringanExtra::use_panelset()
```

```{r xaringanExtra-clipboard, echo=FALSE}
# these allow any code snippets to be copied to the clipboard so they 
# can be pasted easily
htmltools::tagList(
    xaringanExtra::use_clipboard(
        button_text = "<i class=\"fa fa-clipboard\"></i>",
        success_text = "<i class=\"fa fa-check\" style=\"color: #90BE6D\"></i>",
    ),
    rmarkdown::html_dependency_font_awesome()
)
```

```{r xaringan-extras, echo=FALSE}
xaringanExtra::use_tile_view()

```

# `r rmarkdown::metadata$title`
### `r rmarkdown::metadata$author`
### `r format(Sys.time(), "%B %d, %Y")`

---

# Purpose and Agenda

We have some data and want to develop a prediction model. Supervised machine learning is suited to this aim. In particular, in this learning lab, we explore how we can train a computer to predict students' passing a course. We use a large data set, the Open University Learning Analytics Dataset (OULAD), focusing on student data at this point. Our model at this point is relatively simple, a generalized linear model.

## What we'll do in this presentation

- Discussion 1
- Key Concepts
- Code-along
- Discussion 2
- Introduction to the other parts of this learning lab

---

# Discussion 1

.panelset[

.panel[.panel-name[Background, p. 1]


# What technique should I choose?

Do you have coded data or data with a known outcome -- let's say about K-12 students -- and, do you want to:

- _Predict_ how other students with similar data (but without a known outcome) perform?
- _Scale_ coding that you have done for a sample of data to a larger sample?
- _Provide timely or instantaneous feedback_, like in many learning analytics systems?

<bold><h4><center>Supervised methods may be your best bet</center></h4></bold>

.panel[.panel-name[Background, p. 1]

# What technique should I choose?

Do you not yet have codes/outcomes -- and do you want to?

- _Achieve a starting point_ for qualitative coding, perhaps in a ["computational grounded theory"](https://journals.sagepub.com/doi/full/10.1177/0049124117729703) mode?
- _Discover groups or patterns in your data_ that may be of interest?
- _Reduce the number of variables in your dataset_ to a smaller, but perhaps nearly as explanatory/predictive - set of variables?

<bold><h4><center>Unsupervised methods may be helpful</center></h4></bold>


]
]

.panel[.panel-name[Getting Started]

Provide an example of supervised machine learning in the context of educational research. Discuss why this counts as machine learning.

]

.panel[.panel-name[Digging Deeper]

What data or context are you interested in for your use of ML?

]
]

---

# Key Concepts

.panelset[

.panel[.panel-name[Overview]

- We want to make predictions about an outcome of interest based on predictor variables that we think are related to the outcome. 
- We'll be using a widely-used data set in the learning analytics field:
the [Open University Learning Analytics Dataset
(OULAD)](https://analyse.kmi.open.ac.uk/open_dataset). 
- The OULAD was
created by learning analytics researchers at the United Kingdom-based
Open University. 
- It includes data from post-secondary learners
participation in one of several Massive Open Online Courses (called
*modules* in the OULAD).

]

.panel[.panel-name[Driving Q.]

# Can we predict students' passing of OULAD courses?

- Many students pass these courses, but not all do
- We have data on students' initial characteristics and their interactions in the course
- If we could develop a good prediction model, we could provide additional supports to students--and maybe move the needle on some students succeeding who might not otherwise

]

.panel[.panel-name[OULAD]


We'll be focusing on three files:

- studentInfo, courses, and studentRegistration

These are joined together (see `oulad.R`) for this learning lab. You'll be doing more joining later!

```{r}
students <- read_csv("data/oulad-students.csv")
students %>% head(3)
```

]

.panel[.panel-name[LASER Frame]

# Overview of classification modeling

These align with the LASER Framework (used across topic areas):

1.  **Prepare**: Prior to analysis, we'll take a look at the context
from which our data came, formulate some questions, and load R packages.

2.  **Wrangle**: In the wrangling section, we will
learn some basic techniques for manipulating, cleaning,
transforming, and merging data.

3.  **Explore**: The processes of wrangling and exploring data often go hand in hand.

4.  **Model**: In this step, we carry out the analysis - here, supervised machine learning.

5.  **Communicate**: Interpreting and communicating the results of our findings is the last step

]


.panel[.panel-name[Supervised ML Frame]

1. **Split data** (Prepare)  
1. **Engineer features and write down the recipe** (Wrangle and Explore)  
1. **Specify the model and workflow** (Model)  
1. **Fit model** (Model)
1. **Evaluate accuracy** (Communicate)  

This is the basic process we'll follow for this and the next two learning labs focused on supervised ML

]

.panel[.panel-name[Algo.]


- Algorithms (or estimation procedures - or informally models) refer to the _structure_ and _process_ of estimating the _parameters_ of a model

- This definition provides a wide range of options for what kinds of algorithms we use (from simple to very complex, as we discuss in a later learning lab)

- For now, we focus on a familiar, easy to interpret algorithm (e.g., [1](https://dl.acm.org/doi/abs/10.1145/3448139.3448154?casa_token=skmk5XGbDOUAAAAA:Z0Kl4nyjpOGFA6RuFTiiLWaC_KxH1vkQ72Kr0hetXcumRdvu8tPYlCX12AgHr9aS0Fp3L-Uu0p4), also [this](https://linkinghub.elsevier.com/retrieve/pii/S0895435618310813)), _logistic regression_
- This is a linear model with a binary (*"yes"* or *"no"*) outcome
- It will be a _bad model_ to start us off!

]

.panel[.panel-name[Algo.]


- Algorithms (or estimation procedures - or informally models) refer to the _structure_ and _process_ of estimating the _parameters_ of a model

- This definition provides a wide range of options for what kinds of algorithms we use (from simple to very complex, as we discuss in a later learning lab)

- For now, we focus on a familiar, easy to interpret algorithm (e.g., [1](https://dl.acm.org/doi/abs/10.1145/3448139.3448154?casa_token=skmk5XGbDOUAAAAA:Z0Kl4nyjpOGFA6RuFTiiLWaC_KxH1vkQ72Kr0hetXcumRdvu8tPYlCX12AgHr9aS0Fp3L-Uu0p4), also [this](https://linkinghub.elsevier.com/retrieve/pii/S0895435618310813)), _logistic regression_
- This is a linear model with a binary (*"yes"* or *"no"*) outcome
- It will be a _bad model_ to start us off!

]

.panel[.panel-name[Prediction]

- When doing supervised ML, we focus on predicting an outcome: how well we do this overall and for particular cases (more on how in the next learning lab)
- We _do not_ focus on inference or explanation (i.e., an "explanatory" model): model fit, statistical significance, effect sizes, etc.

]

.panel[.panel-name[Train vs. test]

- A key concept in the context of supervised machine learning is training vs. testing data:
- Training data: Data we use to **fit** (or train, AKA estimate) a supervised machine learning **model** (AKA algorithm)
- Testing data: Data we use to see how well our model did---not used to fit the model
- By splitting out data into training and testing _sets_, we can obtain valid metrics for how good our model is at predicting

--

- Increased bias, in the form of an over-fit model 

]

]

---

# Code-along

.panelset[

.panel[.panel-name[0]

**Loading, setting up: create a .R file in /lab-1 and run this code**

```{r, eval = FALSE, echo = TRUE}
library(tidyverse)
library(tidymodels)

starwars_recoded <- starwars %>% # built-in data available just by typing
    mutate(species = ifelse(species_human == "Human", 1, 0)) # recoding species to create a 0-1 outcome

starwars_recoded %>% 
    count(species) # how many humans are there?
```

]

.panel[.panel-name[1]

**Split data**

```{r, echo = TRUE, eval = FALSE}
train_test_split <- initial_split(starwars_recoded, prop = .80)

data_train <- training(train_test_split)
data_test <- testing(train_test_split)
```

]

.panel[.panel-name[2]

**Engineer features**

```{r, echo = TRUE, eval = FALSE}
# predicting humans based on the independent effects of height and mass
my_rec <- recipe(species_human ~ height + mass, data = data_train)
```

]

.panel[.panel-name[3]

**Specify recipe, model, and workflow**

```{r, echo = TRUE, eval = FALSE}
# specify model
my_mod <-
    logistic_reg() %>% 
    set_engine("glm") %>%
    set_mode("classification")

# specify workflow
my_wf <-
    workflow() %>%
    add_model(my_mod) %>% 
    add_recipe(my_rec)
```

]

.panel[.panel-name[4]

**Fit model**

```{r, echo = TRUE, eval = FALSE}
fitted_model <- fit(my_wf, data = data_train)

final_fit <- last_fit(fitted_model, train_test_split)
```

]

.panel[.panel-name[5]

**Evaluate accuracy**

```{r, echo = TRUE, eval = FALSE}
final_fit %>%
    collect_metrics()
```

]


]

---

# Discussion 2

.panelset[

.panel[.panel-name[Getting Started]

How might presenting the results of a machine learning model differ from presenting those from a more traditional ("explanatory") model? 

]

.panel[.panel-name[Digging Deeper]

Why not use our testing data to evaluate how good our model is?

]

]

---

# Introduction to the other parts of this learning lab

.panelset[

.panel[.panel-name[Reading]

Breiman, L. (2001). Statistical modeling: The two cultures (with comments and a rejoinder by the author). *Statistical Science, 16*(3), 199-231. https://projecteuclid.org/journals/statistical-science/volume-16/issue-3/Statistical-Modeling--The-Two-Cultures-with-comments-and-a/10.1214/ss/1009213726.pdf

]

.panel[.panel-name[Case Study]

- Building a prediction model for students passing the class---based just on student data.
- Work with peers to complete this, reading the text, following links to resources (and the reading), and then completing the required 👉 Your Turn ⤵ tasks
- A key is available, but we strongly encourage you to use it only at the end to check your work, or if you are completely stuck and have tried our recommended troubleshooting steps: https://docs.google.com/document/d/14Jc-KG3m5k1BvyKWqw7KmDD21IugU5nV5edfJkZyspY/edit

]

.panel[.panel-name[Badge]

- Involves applying what you have done through this point in the learning lab to a) extending our model and b) reflecting and planning, after which you will knit and submit your work by publishing to Posit Cloud.

]
]

