<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>Machine Learning Learning Lab 3: Feature Engineering</title>
    <meta charset="utf-8" />
    <meta name="author" content="Dr. Joshua Rosenberg" />
    <meta name="date" content="2023-07-17" />
    <script src="libs/header-attrs-2.22/header-attrs.js"></script>
    <link href="libs/remark-css-0.0.1/default.css" rel="stylesheet" />
    <link href="libs/panelset-0.2.6/panelset.css" rel="stylesheet" />
    <script src="libs/panelset-0.2.6/panelset.js"></script>
    <script src="libs/clipboard-2.0.6/clipboard.min.js"></script>
    <link href="libs/xaringanExtra-clipboard-0.2.6/xaringanExtra-clipboard.css" rel="stylesheet" />
    <script src="libs/xaringanExtra-clipboard-0.2.6/xaringanExtra-clipboard.js"></script>
    <script>window.xaringanExtraClipboard(null, {"button":"<i class=\"fa fa-clipboard\"><\/i>","success":"<i class=\"fa fa-check\" style=\"color: #90BE6D\"><\/i>","error":"Press Ctrl+C to Copy"})</script>
    <link href="libs/font-awesome-6.4.0/css/all.min.css" rel="stylesheet" />
    <link href="libs/font-awesome-6.4.0/css/v4-shims.min.css" rel="stylesheet" />
    <link href="libs/tile-view-0.2.6/tile-view.css" rel="stylesheet" />
    <script src="libs/tile-view-0.2.6/tile-view.js"></script>
    <link rel="stylesheet" href="css/laser.css" type="text/css" />
    <link rel="stylesheet" href="css/laser-fonts.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">

class: clear, title-slide, inverse, center, top, middle










# Machine Learning Learning Lab 3: Feature Engineering
----
### **Dr. Joshua Rosenberg**
### July 17, 2023

---

# Purpose and Agenda

How do we interpret a machine learning model? What else can we say, besides how accurate a model this? This learning lab is intended to help you to answer these questions by examining output from a classification and a regression model. We again use the OULAD, but add an assessment file.

## What we'll do in this presentation

- Discussion 1
- Key Concept: Feature Engineering (Part B)
- Key Concept: Resampling and cross-validation
- Key Concept: The Random Forest algorithm
- Code-along
- Discussion 2
- Introduction to the other parts of this learning lab

---

# Discussion 1

.panelset[

.panel[.panel-name[Background]

- Having discussed ways of interpreting how good a predictive model is, we can consider how to make our model better, having a rigorous framework for answering that question.
    
]

.panel[.panel-name[Conceptual Overview]

- How good is a good enough model _for which metrics_?

]

.panel[.panel-name[Coding Walkthrough]

- For your research context, how predictively good does your model need to be to be used with actual people (i.e., teachers, administrators, parents, and students)?

]
]

---

# Key Concept: Features and Feature Engineering (Part B)

.panelset[

.panel[.panel-name[How?]

- Well, what if we just add the values for these variables directly
- But, that ignores that they are at different time points
    - We could include the time point variable, but that is (about) the same for every student
- OULAD interaction data is this way: the number of _clicks_ per day 
- This data is sometimes called _log-trace_ or _clickstream_ data
    
*What are some other ideas?*
]

.panel[.panel-name[How?]

# A few (other) options

- Raw data points
- Their mean
- Their maximum
- Their variability (standard deviation)
- Their linear slope
- Their quadratic slope

**Each of these may derive from a single _variable_ but may offer predictive utility as distinct _features_**

]

.panel[.panel-name[How?]

Here's a time stamp:


```
## [1] "2023-07-17 09:36:41 EDT"
```

**How could this variable be used as a predictor variable?**

]

.panel[.panel-name[How?]

- Removing those with "near-zero variance"
- Removing ID variables and others that _should not be_ informative
- Imputing missing values
- Extract particular elements (i.e., particular _days_ or _times_) from time-related data 
- Categorical variables: Dummy coding, combining categories
- Numeric variables: Normalizing ("standardizing")

**In this lab, we focus on using [OULAD data](https://analyse.kmi.open.ac.uk/open_dataset) on interactions**

]
]

---

# Key Concept: Resampling and cross-validation

.panelset[

.panel[.panel-name[Data]

# The importance of training data

- Training data is what we use to "learn" from data
- A "check" on your work is your predictions on _test_ set data
  - *Train data*: Outcome data that you use to fit your model
  - *Validation data&lt;sup&gt;1&lt;/sup&gt;*: Data you use to select a particular algorithm (not often used, as we'll discuss!)
  - *Test ("hold-out") data*: Data that you do not use in any way to train your model

]

.panel[.panel-name[Data]

In LL1, we fit and interpreted a single _fit of our model_ (80% training, 20% testing). What if we decided to _add new features_ or _change existing features_?

We'd need to use the same training data to tune a new model---and the same testing data to evaluate its performance. **But**, this could lead to fitting a model based on how well we predict the data that happened to end up in the test set. 

We could be optimizing our model for our testing data; when used with new data, our model could make poor predictions.

]

.panel[.panel-name[Data]

- In short, a challenges arises when we wish to use our training data _more than once_

- Namely, if we repeatedly training an algorithm on the same data and then make changes, we may be tailoring our model to specific features of the testing data

- This is a _very common and pervasive problem_ in machine learning applications

- Resampling conserves our testing data; we don't have to spend it until we've finalized our model

]

.panel[.panel-name[Data]

- Resampling involves blurring the boundaries between training and testing data, _but only for the training split of the data_

- Specifically, it involves combining these two portions of our data into one, iteratively considering some of the data to be for "training" and some for "testing"

- Then, fit measures are **averaged** across these different samples

]


.panel[.panel-name[KFCV]

## *k*-folds cross validation (KFCV)

- One of the most common forms of resampling is *k*-folds cross validation
    - Here, some of the data is considered to be a part of the *training* set 
    - The remaining data is a part of the *testing* set
- How many sets (samples taken through resampling)?
    - This is determined by _k_, number of times the data is resampled
    - When _k_ is equivalent to the number of rows in the data, i.e. "Leave One Out Cross-Validation" (LOOCV) 


]

.panel[.panel-name[KFCV]




```
## # A tibble: 3 × 3
##      id var_a  var_b
##   &lt;int&gt; &lt;dbl&gt;  &lt;dbl&gt;
## 1     1 0.959 0.0192
## 2     2 0.780 0.476 
## 3     3 0.736 0.137
```

Using _k_ = 10, how can we split *n* = 100 cases into ten distinct training and testing sets?

*First resampling*


```r
train &lt;- d[1:90, ]
test &lt;- d[91:100, ]
# then, train the model (using train) and calculate a fit measure (using test)
# repeat for train: 1:80, 91:100, test: 81:90, etc.
# ... through the tenth resampling, after which the fit measures are averaged
```

]


.panel[.panel-name[Determining k]

# But how do you determine what _k_ should be?

- A _historically common value_ for _k_ has been 10
- But, as computers have grown in processing power, setting _k_ equal to the number of rows in the data has become more common

]
]

---

# Random Forests

.panelset[

.panel[.panel-name[Background]

- *Random forests* are extensions of classification trees
- _Classification trees_ are a type of algorithm that use conditional logic ("if-then" statements) in a _nested_ manner
    - For instance, here's a _very, very_ simple tree (from [APM](https://link.springer.com/book/10.1007/978-1-4614-6849-3)):

]

.panel[.panel-name[Algorithm]


```code
if Predictor B &gt;= 0.197 then
| if Predictor A &gt;= 0.13 then Class = 1
| else Class = 2
else Class = 2
```

- Measures are used to determine the splits in such a way that classifies observations into small, homogeneous groups (using measures such as the Gini index and entropy measure)

]

.panel[.panel-name[More complexity]


```code
if Predictor B &gt;= 0.197 then
| if Predictor A &gt;= 0.13 then
    | if Predictor C &lt; -1.04 then Class = 1
    | else Class = 2
else Class = 3
```

As you can imagine, with many variables, these trees can become very complex

]

.panel[.panel-name[Takeaways]

- Random forest is an extension of decision tree modeling whereby a collection of decision trees are sequentially **estimated using training data** - and **validated/tested using testing data**
- Different _samples_ of predictors are sampled for inclusion in each individual tree
- Highly complex and non-linear relationships between variables can be estimated
- Each tree is independent of every other tree  
- For classification ML, the final output is the category/group/class selected by individual trees
- For regression ML, the mean or average prediction of the individual trees is returned
]

.panel[.panel-name[For later]

- There are several important tuning parameters for these models:
    - the number of predictor variables that are randomly sampled for each split (`mtry`)
    - the minimum number of data points required to execute a split into branches (`min_n`)
    - the number of trees estimated as a part of the "forest" (`trees`)
- These tuning parameters, broadly, balance predictive performance with the training data with how well the model will perform on new data 

]
]

---


# Coding Walkthrough

.panelset[

.panel[.panel-name[ggplot2]


```r
library(ggrepel)

ggplot(starwars, aes(x = height, label = name)) +
    geom_histogram()
```

]

.panel[.panel-name[ggplot2]


```r
library(ggrepel)

ggplot(starwars, aes(x = height, y = mass, label = name)) +
    geom_point() +
    geom_label_repel()
```
]


.panel[.panel-name[vfcv]


```r
# during Step 1
kfcv &lt;- vfold_cv(data_train, v = 20) # this differentiates this from what we did before
# before, we simple used data_train to fit our model
kfcv
```
]

.panel[.panel-name[vfcv]



]

.panel[.panel-name[vfcv]

```r
# during Step 4
fitted_model_resamples &lt;- fit_resamples(my_wf, resamples = vfcv, metrics = class_metrics) # instead of fit()
```
]

.panel[.panel-name[vfcv]


```r
# during Step 5
collect_metrics(fitted_model_resamples)
```
]

.panel[.panel-name[vip]


```r
# during Step 5
final_fit %&gt;% 
    pluck(".workflow", 1) %&gt;%   
    pull_workflow_fit() %&gt;% 
    vip(num_features = 10)
```
]

    
]

---

# Discussion 2

.panelset[

.panel[.panel-name[Reflecting]

- Why is resampling (cross-validation) important?

]

.panel[.panel-name[Applying]


- Which feature engineering steps might you need to take with the data (or kind of data) you plan to use?

]
]

---

# Introduction to the other parts of this learning lab

.panelset[

.panel[.panel-name[Readings]
    
Baker, R. S., Esbenshade, L., Vitale, J., &amp; Karumbaiah, S. (2023). Using Demographic Data as Predictor Variables: a Questionable Choice. *Journal of Educational Data Mining, 15*(2), 22-52.

And Rodriguez et al. (2021) and Gobert et al. (2013) (*optional*)
]

.panel[.panel-name[Case Study]

- Using interaction data
- Adding features 
- Interpreting the change in our predictions

]

.panel[.panel-name[Badge]

- Considering the use of demographic data as features 
- Adding _activity-specific_ interaction types

]
]

    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "default",
"highlightLines": true,
"highlightLanguage": "r",
"countIncrementalSlides": false,
"ratio": "16:9",
"slideNumberFormat": "<div class=\"progress-bar-container\">\n <div class=\"progress-bar\" style=\"width: calc(%current% / %total% * 100%);\">\n </div>\n</div>"
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
// add `data-at-shortcutkeys` attribute to <body> to resolve conflicts with JAWS
// screen reader (see PR #262)
(function(d) {
  let res = {};
  d.querySelectorAll('.remark-help-content table tr').forEach(tr => {
    const t = tr.querySelector('td:nth-child(2)').innerText;
    tr.querySelectorAll('td:first-child .key').forEach(key => {
      const k = key.innerText;
      if (/^[a-z]$/.test(k)) res[k] = t;  // must be a single letter (key)
    });
  });
  d.body.setAttribute('data-at-shortcutkeys', JSON.stringify(res));
})(document);
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
