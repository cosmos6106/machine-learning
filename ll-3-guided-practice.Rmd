---
title: 'Learning Lab 3 Guided Practice'
author: "Dr. Joshua Kellogg"
date: "`r format(Sys.Date(),'%B %e, %Y')`"
output:
  html_document:
    toc: yes
    toc_depth: 4
    toc_float: yes
    code_folding: show
    code_download: TRUE
editor_options:
  markdown:
    wrap: 72
bibliography: lit/references.bib
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

In the overview presentation for this learning lab, we considered five steps in our supervised machine learning process. Those steps are mirrored here---with the addition of a preamble step whereby we load and process the data.

## Step 0: Loading and setting up

First, let's load the packages we'll use---the familiar {tidyverse} and several others focused on modeling. Like in earlier learning labs, click the green arrow to run the code chunk.

```{r}
library(tidyverse)
library(here)
library(tidymodels)
library(vip)
library(ranger)
```

Next, we'll load two data sources, one with the tweets, the other with our qualitative codes. 

*Note*: We created a means of visualizing the threads to make coding them easier; that's here and it provides a means of seeing what the raw data is like: https://jmichaelrosenberg.shinyapps.io/ngsschat-shiny/

```{r}
d <- read_rds(here("data", "ngsschat-data.rds"))

codes <- read_csv(here("data", "ngsschat-qualitative-codes.csv"))
```

We'll do some processing of the data here. This could seem like a step to skip, but it's quite important as perhaps the most important part of any machine learning model is the data that goes into it. Here, read the comments after each line of code, and then run the code chunk to proceed. 

Here, you'll run all of this code, focusing on manually and then automatically calculating fit measures across the different samples.


.panelset[

.panel[.panel-name[1]

**Split data**

```{r panel-chunk-1, echo = TRUE, eval = FALSE}
library(tidymodels) # doesn't load forcats, stringr, readr from tidyverse
library(readr)
library(here)
library(vip)

d <- read_csv(here("spring-workshop", "data-to-model.csv"))

d <- select(d, -time_spent) # this is another continuous outcome

train_test_split <- initial_split(d, prop = .70)

data_train <- training(train_test_split)

kfcv <- vfold_cv(data_train)

```
]

.panel[.panel-name[2]

**Engineer features**

```{r panel-chunk-2, echo = TRUE, eval = FALSE}
# pre-processing/feature engineering

# d <- select(d, student_id:final_grade, subject:percomp) # selecting the contextual/demographic variables
# and the survey variables

d <- d %>% select(-student_id)

sci_rec <- recipe(final_grade ~ ., data = d) %>% 
    add_role(course_id, new_role = "ID variable") %>% # this can be any string
    step_novel(all_nominal_predictors()) %>% 
    step_normalize(all_numeric_predictors()) %>%
    step_dummy(all_nominal_predictors()) %>% 
    step_nzv(all_predictors()) %>% 
    step_impute_knn(all_predictors(), all_outcomes())
```
]

.panel[.panel-name[3]

**Specify recipe, model, and workflow**
 
```{r panel-chunk-3, echo = TRUE, eval = FALSE}
# specify model
rf_mod_many <-
    rand_forest(mtry = tune(),
                min_n = tune()) %>%
    set_engine("ranger", importance = "impurity") %>%
    set_mode("regression")

# specify workflow
rf_wf_many <-
    workflow() %>%
    add_model(rf_mod_many) %>% 
    add_recipe(sci_rec)

```
]
 
.panel[.panel-name[4]

**Fit model**

```{r panel-chunk-4, echo = TRUE, eval = FALSE}
# specify tuning grid
finalize(mtry(), data_train)
finalize(min_n(), data_train)

tree_grid <- grid_max_entropy(mtry(range(1, 15)),
                              min_n(range(2, 40)),
                              size = 10)

# fit model with tune_grid
tree_res <- rf_wf_many %>% 
    tune_grid(
        resamples = kfcv,
        grid = tree_grid,
        metrics = metric_set(rmse, mae, rsq)
    )
```

]

.panel[.panel-name[5]

**Fit model (part 2)**

```{r panel-chunk-4b, echo = TRUE, eval = FALSE}
# examine best set of tuning parameters; repeat?
show_best(tree_res, n = 10)

# select best set of tuning parameters
best_tree <- tree_res %>%
    select_best()

# finalize workflow with best set of tuning parameters
final_wf <- rf_wf_many %>% 
    finalize_workflow(best_tree)

# fit split data (separately)
final_fit <- final_wf %>% 
    last_fit(train_test_split, metrics = metric_set(rmse, mae, rsq))
```
]

.panel[.panel-name[6]

**Evaluate accuracy**

```{r panel-chunk-5, echo = TRUE, eval = FALSE}
# variable importance plot
final_fit %>% 
    pluck(".workflow", 1) %>%   
    pull_workflow_fit() %>% 
    vip(num_features = 10)

# fit stats
final_fit %>%
    collect_metrics()

# test set predictions
final_fit %>%
    collect_predictions() 
```
]
]