<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>Machine Learning Learning Lab 4: Unsupervised Methods</title>
    <meta charset="utf-8" />
    <meta name="author" content="Dr. Joshua Rosenberg" />
    <meta name="date" content="2023-07-18" />
    <script src="libs/header-attrs-2.22/header-attrs.js"></script>
    <link href="libs/remark-css-0.0.1/default.css" rel="stylesheet" />
    <link href="libs/panelset-0.2.6/panelset.css" rel="stylesheet" />
    <script src="libs/panelset-0.2.6/panelset.js"></script>
    <link rel="stylesheet" href="css/laser.css" type="text/css" />
    <link rel="stylesheet" href="css/laser-fonts.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">


class: clear, title-slide, inverse, center, top, middle









# Machine Learning Learning Lab 4: Unsupervised Methods
----
### **Dr. Joshua Rosenberg**
### July 18, 2023

---


# Purpose and Agenda

The previous three learning labs involved the use of data with known outcome variables in the first three learning labs. Accordingly, we explored different aspects of supervised machine learning. Unsupervised machine learning methods can be used in such cases. Herein, we use Latent Profile Analysis with quantified, transcribed audio data from mathematics classrooms. We interpret the output of Latent Profile Analysis from a Computational Grounded Theory approach.

## What we'll do in this presentation

- Discussion 1
- Key Concepts
- Code-along
- Discussion 2
- Introduction to the other parts of this learning lab

---

# Discussion 1

.panelset[

panel[.panel-name[Background p1]


### What technique should I choose?

Do you have coded data or data with a known outcome -- let's say about K-12 students -- and, do you want to:

- _Predict_ how other students with similar data (but without a known outcome) perform?
- _Scale_ coding that you have done for a sample of data to a larger sample?
- _Provide timely or instantaneous feedback_, like in many learning analytics systems?

&lt;bold&gt;&lt;h4&gt;&lt;center&gt;Supervised methods may be your best bet&lt;/center&gt;&lt;/h4&gt;&lt;/bold&gt;
]

.panel[.panel-name[Background p2]

### What technique should I choose?

Do you not yet have codes/outcomes -- and do you want to?

- _Achieve a starting point_ for qualitative coding, perhaps in a ["computational grounded theory"](https://journals.sagepub.com/doi/full/10.1177/0049124117729703) mode?
- _Discover groups or patterns in your data_ that may be of interest?
- _Reduce the number of variables in your dataset_ to a smaller, but perhaps nearly as explanatory/predictive - set of variables?

&lt;bold&gt;&lt;h4&gt;&lt;center&gt;Unsupervised methods may be helpful&lt;/center&gt;&lt;/h4&gt;&lt;/bold&gt;


]

.panel[.panel-name[Getting Started]

- For what kinds of specific studies or use cases might unsupervised methods be helpful?

]

.panel[.panel-name[Digging Deeper]

- For what kinds of specific studies or use cases might unsupervised methods be helpful, in general?

]
]

---

# Key Concepts: Unsupervised methods and LPA

.panelset[

.panel[.panel-name[Background]

- Until now, we've used coded data to _train_ an algorithm
    - In short, we've used _supervised_ machine learning
    - But, we may not yet have codes; what options to do we have in such situations?
- We can turn to _unsupervised_ machine learning (UML) methods
- We answer this question in the context of *multimodal* data, or data
from multiple channels, including not only the kinds of digital trace
data and survey data, but also data from audio and video channels. This
kind of data is often rich, but hard to interpret at a granular level.

]

.panel[.panel-name[Background]

- We'll be using audio data from mathematics classrooms collected as a
part of Dyer's [*Learning Through Teaching* (LTT)
project](https://www.proquest.com/openview/01af3361c531b12ea3caeda8b85b31fa/1?pq-origsite=gscholar&amp;cbl=18750).

- **Broader data set**: 100s of hours of video and audio
- **Specific data set**: around 3 hours of transcribed audio data (via
[Whisper](https://github.com/bnosac/audio.whisper)) that we further analyzed for
the different affective or emotional sentiment it evidences

]

.panel[.panel-name[UML]

- Does not require coded data; one way to think about unsupervised ML is that its purpose is to discover codes/labels
- Is used to discover groups among observations/cases or to summarize across variables
- Can be used in an _exploratory mode_ (see [Nelson, 2020](https://journals.sagepub.com/doi/full/10.1177/0049124118769114?casa_token=EV5XH31qbyAAAAAA%3AFg09JQ1XHOOzlxYT2SSJ06vZv0jG-s4Qfz8oDIQwh2jrZ-jrHNr7xZYL2FwnZtZiokhPalvV1RL2Bw)) 
- **Warning**: The results of unsupervised ML _cannot_ directly be used to provide codes/outcomes for supervised ML techniques 

]

.panel[.panel-name[UML]

- We can use unsupervised machine learning methods with a range of data types
    - Structured data:
        - Numeric data
        - Categorical data
    - Unstructured data:
        - Text
        - Images
        - Video

**We'll focus here on structured, numeric data** as a way into using these methods
]


.panel[.panel-name[LPA]

- Latent Profile Analysis can be considered to be an unsupervised machine learning method suited to the analysis of structured, numeric data
- Historically, it has been common for educational researchers (and psychologists) to estimate such models using proprietary software--MPlus, but, a package in R is now available [tidyLPA](https://data-edu.github.io/tidyLPA/index.html)
- There are several key steps in LPA:
    1. Choosing which variables to include
    1. Determining the number of profiles
    1. Interpreting the profile

]
]

---

# Key Concepts: Combining qual. and ML methods

.panelset[

.panel[.panel-name[GGT]

- To draw a connection between LPA and machine learning, we'll consider its use in a part of a broader frame, _Computational Grounded Theory_
- Laura Nelson developed this approach in a pioneering paper ([Nelson, 2020](https://journals.sagepub.com/doi/full/10.1177/0049124117729703))
- It involves three steps:
    1. Unsupervised machine learning to _explore_ the data
    2. Careful qualitative analysis of the raw data _and_ the output from step 1
    3. Validation of the revised codes that result from steps 1 and 2

]

.panel[.panel-name[GGT]

- We can consider the results of LPA to not be a _final_, but an _initial_ step in the analysis
- After step 1 of computational grounded theory, the codes can be interrogated more deeply using _qualitative_ methods
- Then, the resulting codes can be validated:
    - Expert review
    - Referral to criterion/varied sources of validity evidence
    - Supervised machine learning methods
]

.panel[.panel-name[GGT in STEM education]

- In [Rosenberg and Krist (2021)](https://link.springer.com/article/10.1007/s10956-020-09862-4), students' written responses were the raw (unstructured) data that was used
- Though a coding frame existed, it was not well suited to the specific data that was available
- At the same time, there was _a lot_ of data available
- The three steps of computational grounded theory were carried out:
    1. Unsupervised exploration of the textual data (topic modeling)
    2. Careful qualitative analysis/reading of the textual data and the topics
    3. Validation (using supervised machine learning methods)
]

.panel[.panel-name[UML in STEM education]

- [Kubsch et al. (2023)](https://onlinelibrary.wiley.com/doi/full/10.1002/tea.21803) ask how machine learning can be used in ways _beyond automation_ and the scaling of existing coding  
- Unsupervised methods play a key role here  
- *Distributing Epistemic Functions and Tasks (DEFT)* highlights the functions and tasks that pertain to generating knowledge that can be carried out by either skilled researchers or machine learning algorithms
    - Asking questions
    - Analyzing data
    - Interpreting findings
    
]

]

---

# Code-along

.panelset[

.panel[.panel-name[`estimate_profiles()`]


```r
pisaUSA15 %&gt;% 
    select(broad_interest, enjoyment, self_efficacy) %&gt;%
    estimate_profiles(3) # estimate 3 profiles
```
    
*N.b.*: we can use `single_imputation()` to impute missing data.

]

.panel[.panel-name[`plot_profiles()`]


```r
pisaUSA15 %&gt;% 
    select(broad_interest, enjoyment, self_efficacy) %&gt;%
    estimate_profiles(3) %&gt;% 
    plot_profiles()
```

]

.panel[.panel-name[`compare_solutions()`]


```r
pisaUSA15 %&gt;%
    select(broad_interest, enjoyment, self_efficacy) %&gt;%
    estimate_profiles(1:5) %&gt;% 
    compare_solutions(statistics = c("AIC", "BIC"))
```

]

.panel[.panel-name[Other]

```r
get_estimates(m4)
get_data(m4)
get_fit(m4)
```
]
]

---

# Discussion 2


.panelset[

.panel[.panel-name[Discussion]

- For what context/purpose might _discovering patterns or themes_ in data be helpful?

]


.panel[.panel-name[Applying]

- Which data might you use for **unsupervised methods**?

]
]

---

# Introduction to the other parts of this learning lab

.panelset[

.panel[.panel-name[Readings]

&gt; Commeford, K., Brewe, E., &amp; Traxler, A. (2022). Characterizing active
&gt; learning environments in physics using latent profile analysis.
&gt; Physical Review Physics Education Research, 18(1).

&gt; Rosenberg, J. M., &amp; Krist, C. (2021). Combining machine learning and
&gt; qualitative methods to elaborate students' ideas about the generality
&gt; of their model-based explanations. *Journal of Science Education and
&gt; Technology, 30*, 255-267.

Optionally, Rosenberg et al. (2019)

]

.panel[.panel-name[Case study]

- Doing some heady data wrangling with the transcribed audio data, then estimating profiles for the LTT that point to moments during classes with potentially different emotional valences
- Interrogating these profiles further in a _computational grounded theory_ mode

]

.panel[.panel-name[Badge]

- Estimating profiles using your own data
- Reflecting on a study related to your research interests using LPA

]
]

---

# *fin*

We hope to see you in the ML topic area learning labs!

- *Dr. Joshua Rosenberg* (jmrosenberg@utk.edu; https://joshuamrosenberg.com)
- *Dr. Peng  He* (hepeng1@msu.edu)

[These slides (Introductory Presentation)](https://laser-institute.github.io/machine-learning/introductory-presentation.html#1)

[General troubleshooting tips for R and RStudio](https://docs.google.com/document/d/14Jc-KG3m5k1BvyKWqw7KmDD21IugU5nV5edfJkZyspY/edit)
    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "default",
"highlightLines": true,
"highlightLanguage": "r",
"countIncrementalSlides": false,
"ratio": "16:9",
"slideNumberFormat": "<div class=\"progress-bar-container\">\n <div class=\"progress-bar\" style=\"width: calc(%current% / %total% * 100%);\">\n </div>\n</div>"
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
// add `data-at-shortcutkeys` attribute to <body> to resolve conflicts with JAWS
// screen reader (see PR #262)
(function(d) {
  let res = {};
  d.querySelectorAll('.remark-help-content table tr').forEach(tr => {
    const t = tr.querySelector('td:nth-child(2)').innerText;
    tr.querySelectorAll('td:first-child .key').forEach(key => {
      const k = key.innerText;
      if (/^[a-z]$/.test(k)) res[k] = t;  // must be a single letter (key)
    });
  });
  d.body.setAttribute('data-at-shortcutkeys', JSON.stringify(res));
})(document);
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
